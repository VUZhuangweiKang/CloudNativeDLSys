{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader Configurations:\n",
    "batch_size = 512\n",
    "num_workers = 8\n",
    "prefetch_factor = 2\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"kubectl cluster-info | grep 'Kubernetes master' | awk '/http/ {print $NF}' | cut -d '/' -f 3\"\n",
    "rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "MASTER = rlt.stdout.split(':')[0]\n",
    "prom_url = \"http://10.140.81.235:30909/api/v1/query\"\n",
    "\n",
    "def measure_memory(dltdeploy):\n",
    "    memory_data = []\n",
    "    pod_name = None\n",
    "    instance = None\n",
    "    while True:\n",
    "        tmp = exec(command=f\"kubectl get dltdeployment {dltdeploy}\")\n",
    "        if len(tmp) == 0:\n",
    "            return instance, pod_name, memory_data\n",
    "        else:\n",
    "            query = 'container_memory_usage_bytes{container=~\"%s.*\", namespace=\"default\"}' % dltdeploy\n",
    "            response = requests.get(prom_url, params={'query': query}, timeout=3)\n",
    "            result = json.loads(response.content.decode('utf-8'))['data']['result']\n",
    "            memory_metric = {}\n",
    "            # if len(result) == 0 and len(memory_data) > 0:\n",
    "            #     return instance, pod_name, memory_data\n",
    "            \n",
    "            for item in result:\n",
    "                pod_name = item['metric']['pod']\n",
    "                if '.' not in pod_name:\n",
    "                    container_name = item['metric']['container']\n",
    "                    instance = item['metric']['instance']\n",
    "                    memory_metric[container_name] = item['value'][1]\n",
    "            \n",
    "            if len(memory_metric) > 0:\n",
    "                memory_data.append(memory_metric)\n",
    "            time.sleep(5)\n",
    "\n",
    "def exec(command):\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"http://192.5.86.247:32500\"\n",
    "credential = {\n",
    "    \"username\": \"docgroup\",\n",
    "    \"password\": \"docgroup\",\n",
    "    \"s3auth\": {\n",
    "        \"aws_access_key_id\": \"AKIASTYAKBJHWYDKMYWE\",\n",
    "        \"aws_secret_access_key\": \"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\",\n",
    "        \"region_name\": \"us-east-1\",\n",
    "    }\n",
    "}\n",
    "resp = requests.post(url=f\"{server}/connect\", json=credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp1\n",
    "Evaluate the dataset merging algorithm with our job and dataset placement algorithm:\n",
    "- Scenario: 1-job/1-worker\n",
    "- Datasets: deepspeech, LibriSpeech\n",
    "- Baselines:\n",
    "    - No merging: load individual files\n",
    "    - Fixed Size Block: enumerate and benchmark multiple block sizes until meeting the early stop condition. (<= 5% imp for 3 block sizes) \n",
    "- Metrics:\n",
    "    - Data loading time\n",
    "    - Job completion time\n",
    "    - Memory utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = {\n",
    "    \"name\": \"Deepspeech\",\n",
    "    \"credential\": credential,\n",
    "    \"gangScheduling\": False,\n",
    "    \"datasource\": {\n",
    "        \"name\": \"LibriSpeech-train-100\",\n",
    "        \"bucket\": \"vuzhuangwei\",\n",
    "        \"keys\": {\n",
    "            \"train\": [\"LibriSpeech-train-100/train\"]\n",
    "        }\n",
    "    },\n",
    "    \"jobs\": [\n",
    "        {\n",
    "            \"name\": \"job1\",\n",
    "            \"workerContainer\": {\n",
    "                \"name\": \"deepspeech\",\n",
    "                \"image\": \"zhuangweikang/deepspeech-dev:latest\",\n",
    "                \"workingDir\": \"/app\",\n",
    "                \"command\": [\"/bin/sh\",\"-c\"],\n",
    "                \"tty\": True,\n",
    "                \"stdin\": True\n",
    "            },\n",
    "            \"numWorkers\": 1\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_compute_times = [0.1, 0.25, 0.5, 0.75, 1.0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: No Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "!kubectl delete dltdeployment --all --force --grace-period=0\n",
    "!kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "!kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "!cd manager && python3 deploy.py\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 1:\n",
    "        break\n",
    "    time.sleep(3)\n",
    "!cd manager-worker && python3 deploy.py\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 3:\n",
    "        break\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"experiments/exp1/baseline1\"\n",
    "!kubectl delete dltdeployment --all --force --grace-period=0\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep deepspeech | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 0:\n",
    "        break\n",
    "    time.sleep(3)\n",
    "    \n",
    "for compute_time in sim_compute_times:\n",
    "    if os.path.exists(f\"{base_dir}/sim_compute_time={compute_time}\"):\n",
    "        continue\n",
    "    train_cmd = f\"python3 train_wrapper.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs {num_epochs} --batch-size {batch_size}\"\n",
    "    # train_cmd = \"bash\"\n",
    "    deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "    resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "    flag = False\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep deepspeech | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        if len(result) > 0:\n",
    "            flag = True\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 1:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "    dltdeploy = exec(command=cmd).strip('\\n')\n",
    "    assert len(dltdeploy) > 0\n",
    "    print(f\"dltdeploy: {dltdeploy}\")\n",
    "    \n",
    "    print('measuring memory...')\n",
    "    node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy)\n",
    "    metric_dir = f'{base_dir}/{dltdeploy_pod}'\n",
    "    if not os.path.exists(metric_dir):\n",
    "        os.makedirs(metric_dir)\n",
    "    with open(f'{metric_dir}/readme.txt', 'w') as f:\n",
    "        f.write(f\"sim_compute_time: {compute_time}\")\n",
    "    np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "    cmd = \"kubectl describe node %s  | grep InternalIP | awk '{print $2}'\" % node\n",
    "    rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    node_ip = rlt.stdout.strip('\\n')\n",
    "    !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "    !mv {metric_dir} {base_dir}/sim_compute_time={compute_time}\n",
    "    !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "    !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "    time.sleep(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: Fixed Block Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_sizes = list(range(500, 2000, 500))\n",
    "base_dir = \"experiments/exp1/baseline2\"\n",
    "\n",
    "# for compute_time in sim_compute_times[1:2]:\n",
    "#     for block_size in block_sizes:\n",
    "\n",
    "# for compute_time, block_size in [(0.25, 121), (0.5, 41), (1.0, 121), (1.5, 61), (2, 261)]:\n",
    "for compute_time, block_size, threadpool_size in [(0.75, 140, 1)]:\n",
    "    print(f\"compute_time: {compute_time}, block_size: {block_size}\")\n",
    "    \n",
    "    if os.path.exists(f\"{base_dir}/sim_compute_time={compute_time}-block_size={block_size}\"):\n",
    "        continue\n",
    "    \n",
    "    print('clear manager and manager worker...')\n",
    "    !kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "    !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "    \n",
    "    !kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "    !kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "    \n",
    "    print('deploy manager and manager worker...')\n",
    "    !cd manager && python3 deploy.py 1 {block_size} {threadpool_size}\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 1:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    !cd manager-worker && python3 deploy.py\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 3:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "    \n",
    "    train_cmd = f\"python3 train_wrapper.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs 1 --batch-size {batch_size}\"\n",
    "    # train_cmd = \"bash\"\n",
    "    deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "    resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "    while True:\n",
    "        output = exec(\"kubectl get pods | grep deepspeech\")\n",
    "        output = output.strip().split('\\n')\n",
    "        result = []\n",
    "        for i in range(len(output)):\n",
    "            output[i] = output[i].split(' ')\n",
    "            item = [x for x in output[i] if len(x) > 0]\n",
    "            if len(item) > 0:\n",
    "                result.append(item)\n",
    "        if len(result) > 0:\n",
    "            result = np.array(result)\n",
    "            pods = result[:, 0]\n",
    "            status = result[:, 2]\n",
    "            pods = ['.' in pod for pod in pods]\n",
    "            if sum(pods) == 0:\n",
    "                status = [item=='Running' for item in status]\n",
    "                if sum(status) >= 1:\n",
    "                    break\n",
    "        time.sleep(3)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "    dltdeploy = exec(command=cmd).strip('\\n')\n",
    "    assert len(dltdeploy) > 0\n",
    "    print(f\"dltdeploy: {dltdeploy}\")\n",
    "\n",
    "    print('start measuring memory...')\n",
    "    node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy) \n",
    "    metric_dir = f'{base_dir}/{dltdeploy_pod}/'\n",
    "    if not os.path.exists(metric_dir):\n",
    "        os.makedirs(metric_dir)\n",
    "    np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "    cmd = \"kubectl describe node %s | grep InternalIP | awk '{print $2}'\" % node\n",
    "    rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    node_ip = rlt.stdout.strip('\\n')\n",
    "    !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "    new_metric_dir = f'{base_dir}/sim_compute_time={compute_time}-block_size={block_size}/'\n",
    "    !mv {metric_dir} {new_metric_dir}\n",
    "    !mv /nfs/hdd/{dltdeploy}.csv {new_metric_dir}/\n",
    "    !mv /nfs/hdd/opt_config {new_metric_dir}/\n",
    "\n",
    "    total_load_time = np.sum(np.load(f\"{new_metric_dir}/data_load_time.npy\"))\n",
    "    total_compute_time = np.sum(np.load(f\"{new_metric_dir}/compute_time.npy\"))\n",
    "    latency = total_load_time + total_compute_time\n",
    "    print(f\"completion_time: {latency}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"experiments/exp1/ours\"\n",
    "\n",
    "for compute_time in sim_compute_times:\n",
    "    print('clear manager and manager worker...')\n",
    "    !kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "    !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "    !kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "    !kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "\n",
    "    print('deploy manager and manager worker...')\n",
    "    !cd manager && python3 deploy.py 1\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 1:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    !cd manager-worker && python3 deploy.py\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 3:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "\n",
    "    # !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "    !ssh cc@10.140.81.235 vmtouch -e /nfs/ssd/\n",
    "    train_cmd = f\"python3 train_wrapper.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs {num_epochs} --batch-size {batch_size}\"\n",
    "    # train_cmd = \"bash\"\n",
    "    deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "    resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "    while True:\n",
    "        time.sleep(3)\n",
    "        output = exec(\"kubectl get pods | grep deepspeech\")\n",
    "        output = output.strip().split('\\n')\n",
    "        result = []\n",
    "        for i in range(len(output)):\n",
    "            output[i] = output[i].split(' ')\n",
    "            item = [x for x in output[i] if len(x) > 0]\n",
    "            if len(item) > 0:\n",
    "                result.append(item)\n",
    "        if len(result) > 0:\n",
    "            result = np.array(result)\n",
    "            pods = result[:, 0]\n",
    "            status = result[:, 2]\n",
    "            pods = ['.' in pod for pod in pods]\n",
    "            if sum(pods) == 0:\n",
    "                status = [item=='Running' for item in status]\n",
    "                if sum(status) >= 1:\n",
    "                    break\n",
    "    time.sleep(10)\n",
    "\n",
    "    cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "    dltdeploy = exec(command=cmd).strip('\\n')\n",
    "    assert len(dltdeploy) > 0\n",
    "    print(f\"dltdeploy: {dltdeploy}\")\n",
    "    \n",
    "    print('start measuring memory...')\n",
    "    node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy)\n",
    "    if '.' in dltdeploy_pod:\n",
    "        dltdeploy_pod = dltdeploy_pod.split('.')[0]\n",
    "    metric_dir = f'{base_dir}/{dltdeploy_pod}/'\n",
    "    if not os.path.exists(metric_dir):\n",
    "        os.makedirs(metric_dir)\n",
    "    np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "    cmd = \"kubectl describe node %s | grep InternalIP | awk '{print $2}'\" % node\n",
    "    rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    node_ip = rlt.stdout.strip('\\n')\n",
    "    !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "    new_metric_dir = f'{base_dir}/sim_compute_time={compute_time}'\n",
    "    !mv {metric_dir} {new_metric_dir}\n",
    "    !mv /nfs/hdd/{dltdeploy}.csv {new_metric_dir}/\n",
    "    !mv /nfs/hdd/opt_config {new_metric_dir}/\n",
    "\n",
    "    total_load_time = np.sum(np.load(f\"{new_metric_dir}/data_load_time.npy\"))\n",
    "    total_compute_time = np.sum(np.load(f\"{new_metric_dir}/compute_time.npy\"))\n",
    "    latency = total_load_time + total_compute_time\n",
    "    print(f\"completion_time: {latency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
