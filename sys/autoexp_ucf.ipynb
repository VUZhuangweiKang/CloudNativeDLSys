{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader Configurations:\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "prefetch_factor = 2\n",
    "mini_batches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"kubectl cluster-info | grep 'Kubernetes master' | awk '/http/ {print $NF}' | cut -d '/' -f 3\"\n",
    "rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "MASTER = rlt.stdout.split(':')[0]\n",
    "prom_url = \"http://10.140.81.235:30909/api/v1/query\"\n",
    "\n",
    "def measure_memory(dltdeploy):\n",
    "    memory_data = []\n",
    "    pod_name = None\n",
    "    instance = None\n",
    "    while True:\n",
    "        tmp = exec(command=f\"kubectl get dltdeployment {dltdeploy}\")\n",
    "        if len(tmp) == 0:\n",
    "            return instance, pod_name, memory_data\n",
    "        else:\n",
    "            query = 'container_memory_usage_bytes{container=~\"%s.*\", namespace=\"default\"}' % dltdeploy\n",
    "            response = requests.get(prom_url, params={'query': query}, timeout=3)\n",
    "            result = json.loads(response.content.decode('utf-8'))['data']['result']\n",
    "            memory_metric = {}\n",
    "            # if len(result) == 0 and len(memory_data) > 0:\n",
    "            #     return instance, pod_name, memory_data\n",
    "            \n",
    "            for item in result:\n",
    "                pod_name = item['metric']['pod']\n",
    "                if '.' not in pod_name:\n",
    "                    container_name = item['metric']['container']\n",
    "                    instance = item['metric']['instance']\n",
    "                    memory_metric[container_name] = item['value'][1]\n",
    "            \n",
    "            if len(memory_metric) > 0:\n",
    "                memory_data.append(memory_metric)\n",
    "            time.sleep(5)\n",
    "\n",
    "def exec(command):\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"http://192.5.86.246:32500\"\n",
    "credential = {\n",
    "    \"username\": \"docgroup\",\n",
    "    \"password\": \"docgroup\",\n",
    "    \"s3auth\": {\n",
    "        \"aws_access_key_id\": \"AKIASTYAKBJHWYDKMYWE\",\n",
    "        \"aws_secret_access_key\": \"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\",\n",
    "        \"region_name\": \"us-east-1\",\n",
    "    }\n",
    "}\n",
    "resp = requests.post(url=f\"{server}/connect\", json=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = {\n",
    "    \"name\": \"UCF101\",\n",
    "    \"credential\": credential,\n",
    "    \"gangScheduling\": False,\n",
    "    \"datasource\": {\n",
    "        \"name\": \"UCF-101\",\n",
    "        \"bucket\": \"vuzhuangwei\",\n",
    "        \"keys\": {\n",
    "            \"train\": [\"UCF-101/train\"]\n",
    "        }\n",
    "    },\n",
    "    \"jobs\": [\n",
    "        \n",
    "        {\n",
    "            \"name\": \"job1\",\n",
    "            \"workerContainer\": {\n",
    "                \"name\": \"ucf\",\n",
    "                \"image\": \"zhuangweikang/ucf-dev:latest\",\n",
    "                \"workingDir\": \"/app\",\n",
    "                \"command\": [\"/bin/sh\",\"-c\"],\n",
    "                \"tty\": True,\n",
    "                \"stdin\": True\n",
    "            },\n",
    "            \"numWorkers\": 1\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_compute_times = [0.25, 0.5, 0.75, 1.0, 1.25]\n",
    "print(\"Compute Times:\", sim_compute_times)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: No Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB shell version v4.2.24\n",
      "connecting to: mongodb://127.0.0.1:27017/CNDLSys?compressors=disabled&gssapiServiceName=mongodb\n",
      "Implicit session: session { \"id\" : UUID(\"3d2776d3-e770-4bb3-baf5-b2845b8514b8\") }\n",
      "MongoDB server version: 4.2.24\n",
      "true\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "daemonset.apps \"manager-worker\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "deployment.apps \"manager\" force deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "!kubectl delete dltdeployment --all --force --grace-period=0\n",
    "!kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "!kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "!cd manager && python3 deploy.py\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 1:\n",
    "        break\n",
    "    time.sleep(3)\n",
    "!cd manager-worker && python3 deploy.py\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 3:\n",
    "        break\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "dltdeploy: ucf101-yqbhq\n",
      "measuring memory...\n",
      "compute_time.npy                              100%  520     1.3MB/s   00:00    \n",
      "data_load_time.npy                            100%  528     1.4MB/s   00:00    \n",
      "io_time.npy                                   100%   32KB  24.0MB/s   00:00    \n",
      "processing_time.npy                           100%   32KB  29.6MB/s   00:00    \n",
      "           Files: 9537\n",
      "     Directories: 6\n",
      "   Evicted Pages: 1266699 (4G)\n",
      "         Elapsed: 0.63408 seconds\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "base_dir = \"experiments/exp1/baseline1\"\n",
    "!kubectl delete dltdeployment --all --force --grace-period=0\n",
    "while True:\n",
    "    result = exec(\"kubectl get pods | grep ucf | awk '{{print $3}}'\")\n",
    "    result = result.split('\\n')\n",
    "    result = [item for item in result if len(item) > 0]\n",
    "    result = [item=='Running' for item in result]\n",
    "    if sum(result) == 0:\n",
    "        break\n",
    "    time.sleep(3)\n",
    "    \n",
    "for compute_time in sim_compute_times[2:3]:\n",
    "    if os.path.exists(f\"{base_dir}/sim_compute_time={compute_time}\"):\n",
    "        continue\n",
    "    train_cmd = f\"python3 main.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs {num_epochs} --batch-size {batch_size} --mini-batches {mini_batches}\"\n",
    "    # train_cmd = \"bash\"\n",
    "    deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "    resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "    flag = False\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep ucf | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        if len(result) > 0:\n",
    "            flag = True\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 1:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "    dltdeploy = exec(command=cmd).strip('\\n')\n",
    "    assert len(dltdeploy) > 0\n",
    "    print(f\"dltdeploy: {dltdeploy}\")\n",
    "    \n",
    "    print('measuring memory...')\n",
    "    node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy)\n",
    "    metric_dir = f'{base_dir}/{dltdeploy_pod}'\n",
    "    if not os.path.exists(metric_dir):\n",
    "        os.makedirs(metric_dir)\n",
    "    with open(f'{metric_dir}/readme.txt', 'w') as f:\n",
    "        f.write(f\"sim_compute_time: {compute_time}\")\n",
    "    np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "    cmd = \"kubectl describe node %s  | grep InternalIP | awk '{print $2}'\" % node\n",
    "    rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    node_ip = rlt.stdout.strip('\\n')\n",
    "    !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "    !mv {metric_dir} {base_dir}/sim_compute_time={compute_time}\n",
    "    !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "    !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "    time.sleep(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: Fixed Block Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_time: 0.5, block_size: 100\n",
      "clear manager and manager worker...\n",
      "MongoDB shell version v4.2.24\n",
      "connecting to: mongodb://127.0.0.1:27017/CNDLSys?compressors=disabled&gssapiServiceName=mongodb\n",
      "Implicit session: session { \"id\" : UUID(\"781b2ae1-ec67-4a7c-a61f-9e5f02f90724\") }\n",
      "MongoDB server version: 4.2.24\n",
      "true\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "           Files: 99\n",
      "     Directories: 6\n",
      "   Evicted Pages: 1262218 (4G)\n",
      "         Elapsed: 0.094369 seconds\n"
     ]
    }
   ],
   "source": [
    "# block_sizes = list(range(100, 2000, 300))\n",
    "block_sizes = list(range(5, 25, 5))\n",
    "base_dir = \"experiments/exp1/baseline2\"\n",
    "\n",
    "for compute_time in [0.75]:\n",
    "    for block_size in [100]:\n",
    "        print(f\"compute_time: {compute_time}, block_size: {block_size}\")\n",
    "        \n",
    "        if os.path.exists(f\"{base_dir}/sim_compute_time={compute_time}-block_size={block_size}\"):\n",
    "            continue\n",
    "        \n",
    "        print('clear manager and manager worker...')\n",
    "        !kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "        !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "        !kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "        !kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "        \n",
    "        print('deploy manager and manager worker...')\n",
    "        !cd manager && python3 deploy.py 1 {block_size}\n",
    "        while True:\n",
    "            result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "            result = result.split('\\n')\n",
    "            result = [item for item in result if len(item) > 0]\n",
    "            result = [item=='Running' for item in result]\n",
    "            if sum(result) >= 1:\n",
    "                break\n",
    "            time.sleep(3)\n",
    "        !cd manager-worker && python3 deploy.py\n",
    "        while True:\n",
    "            result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "            result = result.split('\\n')\n",
    "            result = [item for item in result if len(item) > 0]\n",
    "            result = [item=='Running' for item in result]\n",
    "            if sum(result) >= 3:\n",
    "                break\n",
    "            time.sleep(3)\n",
    "        !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "        \n",
    "        train_cmd = f\"python3 main.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs 1 --batch-size {batch_size} --mini-batches {mini_batches}\"\n",
    "        # train_cmd = \"bash\"\n",
    "        deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "        resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "        while True:\n",
    "            output = exec(\"kubectl get pods | grep ucf\")\n",
    "            output = output.strip().split('\\n')\n",
    "            result = []\n",
    "            for i in range(len(output)):\n",
    "                output[i] = output[i].split(' ')\n",
    "                item = [x for x in output[i] if len(x) > 0]\n",
    "                if len(item) > 0:\n",
    "                    result.append(item)\n",
    "            if len(result) > 0:\n",
    "                result = np.array(result)\n",
    "                pods = result[:, 0]\n",
    "                status = result[:, 2]\n",
    "                pods = ['.' in pod for pod in pods]\n",
    "                if sum(pods) == 0:\n",
    "                    status = [item=='Running' for item in status]\n",
    "                    if sum(status) >= 1:\n",
    "                        break\n",
    "            time.sleep(3)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "        dltdeploy = exec(command=cmd).strip('\\n')\n",
    "        assert len(dltdeploy) > 0\n",
    "        print(f\"dltdeploy: {dltdeploy}\")\n",
    "    \n",
    "        print('start measuring memory...')\n",
    "        node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy) \n",
    "        metric_dir = f'{base_dir}/{dltdeploy_pod}/'\n",
    "        if not os.path.exists(metric_dir):\n",
    "            os.makedirs(metric_dir)\n",
    "        np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "        cmd = \"kubectl describe node %s | grep InternalIP | awk '{print $2}'\" % node\n",
    "        rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        node_ip = rlt.stdout.strip('\\n')\n",
    "        !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "        new_metric_dir = f'{base_dir}/sim_compute_time={compute_time}-block_size={block_size}/'\n",
    "        !mv {metric_dir} {new_metric_dir}\n",
    "        !mv /nfs/hdd/{dltdeploy}.csv {new_metric_dir}/\n",
    "        !mv /nfs/hdd/opt_config {new_metric_dir}/\n",
    "\n",
    "        total_load_time = np.sum(np.load(f\"{new_metric_dir}/data_load_time.npy\"))\n",
    "        total_compute_time = np.sum(np.load(f\"{new_metric_dir}/compute_time.npy\"))\n",
    "        latency = total_load_time + total_compute_time\n",
    "        print(f\"completion_time: {latency}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear manager and manager worker...\n",
      "MongoDB shell version v4.2.24\n",
      "connecting to: mongodb://127.0.0.1:27017/CNDLSys?compressors=disabled&gssapiServiceName=mongodb\n",
      "Implicit session: session { \"id\" : UUID(\"91024a5a-6a5a-42a4-a89c-7aaafc42dc8c\") }\n",
      "MongoDB server version: 4.2.24\n",
      "true\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "daemonset.apps \"manager-worker\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "deployment.apps \"manager\" force deleted\n",
      "deploy manager and manager worker...\n",
      "           Files: 99\n",
      "     Directories: 6\n",
      "   Evicted Pages: 1262218 (4G)\n",
      "         Elapsed: 0.004701 seconds\n",
      "dltdeploy: ucf101-wymfh\n",
      "start measuring memory...\n",
      "compute_time.npy                              100%  520     1.2MB/s   00:00    \n",
      "data_load_time.npy                            100%  528     1.5MB/s   00:00    \n",
      "io_time.npy                                   100%  520     1.5MB/s   00:00    \n",
      "processing_time.npy                           100%   32KB  26.3MB/s   00:00    \n",
      "completion_time: 144.8119547367096\n",
      "clear manager and manager worker...\n",
      "MongoDB shell version v4.2.24\n",
      "connecting to: mongodb://127.0.0.1:27017/CNDLSys?compressors=disabled&gssapiServiceName=mongodb\n",
      "Implicit session: session { \"id\" : UUID(\"5243e70a-edef-4185-bff6-056ddf535121\") }\n",
      "MongoDB server version: 4.2.24\n",
      "true\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "daemonset.apps \"manager-worker\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "deployment.apps \"manager\" force deleted\n",
      "deploy manager and manager worker...\n",
      "           Files: 99\n",
      "     Directories: 6\n",
      "   Evicted Pages: 1262218 (4G)\n",
      "         Elapsed: 0.24127 seconds\n",
      "dltdeploy: ucf101-efhtd\n",
      "start measuring memory...\n",
      "compute_time.npy                              100%  520     1.3MB/s   00:00    \n",
      "data_load_time.npy                            100%  528     1.5MB/s   00:00    \n",
      "io_time.npy                                   100% 1800     4.4MB/s   00:00    \n",
      "processing_time.npy                           100%   32KB  25.1MB/s   00:00    \n",
      "completion_time: 147.2230463027954\n",
      "clear manager and manager worker...\n",
      "MongoDB shell version v4.2.24\n",
      "connecting to: mongodb://127.0.0.1:27017/CNDLSys?compressors=disabled&gssapiServiceName=mongodb\n",
      "Implicit session: session { \"id\" : UUID(\"8c012fdb-7c8d-4b95-89e3-f644756e9fb9\") }\n",
      "MongoDB server version: 4.2.24\n",
      "true\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "No resources found\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "daemonset.apps \"manager-worker\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "deployment.apps \"manager\" force deleted\n",
      "deploy manager and manager worker...\n",
      "           Files: 479\n",
      "     Directories: 6\n",
      "   Evicted Pages: 1262414 (4G)\n",
      "         Elapsed: 0.26246 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m resp \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(url\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mserver\u001b[39m}\u001b[39;00m\u001b[39m/deploy\u001b[39m\u001b[39m\"\u001b[39m, json\u001b[39m=\u001b[39mdeploy)\n\u001b[1;32m     36\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m3\u001b[39;49m)\n\u001b[1;32m     38\u001b[0m     output \u001b[39m=\u001b[39m exec(\u001b[39m\"\u001b[39m\u001b[39mkubectl get pods | grep ucf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = \"experiments/exp1/ours\"\n",
    "num_epochs = 1\n",
    "for compute_time in sim_compute_times[1:]:\n",
    "    print('clear manager and manager worker...')\n",
    "    !kubectl exec mongo-1 -- mongo CNDLSys --eval \"db.Datasets.drop()\"\n",
    "    !kubectl delete dltdeployment --all --force --grace-period=0\n",
    "    !kubectl delete -f manager-worker/daemonset_template.yaml --force --grace-period=0\n",
    "    !kubectl delete -f manager/deploy_template.yaml --force --grace-period=0\n",
    "\n",
    "    print('deploy manager and manager worker...')\n",
    "    !cd manager && python3 deploy.py 1\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 1:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    !cd manager-worker && python3 deploy.py\n",
    "    while True:\n",
    "        result = exec(\"kubectl get pods | grep manager-worker | awk '{{print $3}}'\")\n",
    "        result = result.split('\\n')\n",
    "        result = [item for item in result if len(item) > 0]\n",
    "        result = [item=='Running' for item in result]\n",
    "        if sum(result) >= 3:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "\n",
    "    !ssh cc@{node_ip} vmtouch -e /nfs/ssd/\n",
    "    # !ssh cc@10.140.81.235 vmtouch -e /nfs/ssd/\n",
    "    train_cmd = f\"python3 main.py -j {num_workers} -p 1 --sim-compute-time {compute_time} --epochs {num_epochs} --batch-size {batch_size} --mini-batches {mini_batches}\"\n",
    "    # train_cmd = \"bash\"\n",
    "    deploy['jobs'][0]['workerContainer']['args'] = [train_cmd]\n",
    "    resp = requests.post(url=f\"{server}/deploy\", json=deploy)\n",
    "    while True:\n",
    "        time.sleep(3)\n",
    "        output = exec(\"kubectl get pods | grep ucf\")\n",
    "        output = output.strip().split('\\n')\n",
    "        result = []\n",
    "        for i in range(len(output)):\n",
    "            output[i] = output[i].split(' ')\n",
    "            item = [x for x in output[i] if len(x) > 0]\n",
    "            if len(item) > 0:\n",
    "                result.append(item)\n",
    "        if len(result) > 0:\n",
    "            result = np.array(result)\n",
    "            pods = result[:, 0]\n",
    "            status = result[:, 2]\n",
    "            pods = ['.' in pod for pod in pods]\n",
    "            if sum(pods) == 0:\n",
    "                status = [item=='Running' for item in status]\n",
    "                if sum(status) >= 1:\n",
    "                    break\n",
    "    time.sleep(10)\n",
    "\n",
    "    cmd = \"kubectl get dltdeployment | awk '{print $1}' | tail -n 1\"\n",
    "    dltdeploy = exec(command=cmd).strip('\\n')\n",
    "    assert len(dltdeploy) > 0\n",
    "    print(f\"dltdeploy: {dltdeploy}\")\n",
    "    \n",
    "    print('start measuring memory...')\n",
    "    node, dltdeploy_pod, memory_rlt = measure_memory(dltdeploy)\n",
    "    if '.' in dltdeploy_pod:\n",
    "        dltdeploy_pod = dltdeploy_pod.split('.')[0]\n",
    "    metric_dir = f'{base_dir}/{dltdeploy_pod}/'\n",
    "    if not os.path.exists(metric_dir):\n",
    "        os.makedirs(metric_dir)\n",
    "    np.save(f'{metric_dir}/memory.npy', memory_rlt)\n",
    "    cmd = \"kubectl describe node %s | grep InternalIP | awk '{print $2}'\" % node\n",
    "    rlt = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    node_ip = rlt.stdout.strip('\\n')\n",
    "    !scp -r cc@{node_ip}:/nfs/hdd/{dltdeploy_pod} {base_dir}/\n",
    "    new_metric_dir = f'{base_dir}/sim_compute_time={compute_time}'\n",
    "    !mv {metric_dir} {new_metric_dir}\n",
    "    !mv /nfs/hdd/{dltdeploy}.csv {new_metric_dir}/\n",
    "    !mv /nfs/hdd/opt_config {new_metric_dir}/\n",
    "\n",
    "    total_load_time = np.sum(np.load(f\"{new_metric_dir}/data_load_time.npy\"))\n",
    "    total_compute_time = np.sum(np.load(f\"{new_metric_dir}/compute_time.npy\"))\n",
    "    latency = total_load_time + total_compute_time\n",
    "    print(f\"completion_time: {latency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
